version: '3.8'

services:
  webserver:
    build: 
      context: ./APACHE_AIRFLOW/
      dockerfile: Dockerfile-airflow
    restart: always
    command: > 
      bash -c "airflow db reset -y && 
      airflow db upgrade &&
      airflow db init && 
      airflow users create --username airflow --firstname Airflow --lastname User --role Admin --email airflow@example.com --password airflow && 
      airflow webserver"
    volumes:
      - ./dags:/usr/local/airflow/dags
    ports:
      - 8080:8080
    depends_on:
      - db
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor

  scheduler:
    build: 
      context: ./APACHE_AIRFLOW/
      dockerfile: Dockerfile-airflow
    restart: always
    command: > 
      bash -c "sleep 180 && airflow scheduler"
    volumes:
      - ./dags:/usr/local/airflow/dags
    depends_on:
      - db
      - webserver
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor

  db:
    image: postgres:13
    restart: always
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
      - TZ=America/Lima

  zookeeper:
    build: 
      context: ./APACHE_KAFKA/CONTENEDOR1
      dockerfile: Dockerfile-zookeeper
    ports:
      - 2181:2181
      - 2888:2888
      - 3888:3888
    environment:
      - KAFKA_USER_HOME=/usr/local/kafka
    volumes:
      - ./CONTENEDOR1/apache-zookeeper-3.8.1-bin:/usr/local/kafka  # replace with the actual directory
    restart: always

  kafka:
    build: 
      context: ./APACHE_KAFKA/CONTENEDOR2
      dockerfile: Dockerfile-kafka
    ports:
      - 9092:9092
    environment:
      - KAFKA_USER_HOME=/usr/local/kafka
    volumes:
      - ./CONTENEDOR2/kafka_2.13-3.5.0:/usr/local/kafka  # replace with the actual directory
    depends_on:
      - zookeeper
    restart: always
